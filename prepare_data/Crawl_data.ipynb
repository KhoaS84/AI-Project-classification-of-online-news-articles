{"cells":[{"cell_type":"markdown","metadata":{"id":"UfgNR8kWgcFJ"},"source":["# **1. Thu thập dữ liệu**\n","\n","\n","\n","\n","**Cách thức thu thập**\n","\n","Nguồn dữ liệu: trang báo điện tử VNExpress (https://vnexpress.net), Dân trí (https://dantri.com.vn), Tuổi trẻ (https://tuoitre.vn/).\n","\n","**Quy trình thu thập:**\n","*   Viết script Python để truy cập từng chuyên mục trên các trang web.\n","*   Sử dụng BeautifulSoup để trích xuất các thẻ HTML chứa thông tin cần thiết,\n","dùng Selenium để cuộn trang.\n","*  Lưu dữ liệu vào file CSV với các cột: title, description, content, category, author, link, category.\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1407,"status":"ok","timestamp":1746688051877,"user":{"displayName":"Khoa Lê","userId":"17187553463541410888"},"user_tz":-420},"id":"vBWINDMsturR","outputId":"94b5e9b4-8123-4dbe-ea88-3013ce501f6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"g2YNYif-unIj"},"source":["# Crawl nguồn vnexpress"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"nVQkm7QutbUe"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Bắt đầu crawl danh mục: Sức khỏe\n","Đang crawl trang 1 của danh mục Sức khỏe: https://vnexpress.net/suc-khoe\n","Đang crawl trang 2 của danh mục Sức khỏe: https://vnexpress.net/suc-khoe-p2\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/suc-khoe-p2\n","Đang crawl trang 3 của danh mục Sức khỏe: https://vnexpress.net/suc-khoe-p3\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/suc-khoe-p3\n","Đang crawl trang 4 của danh mục Sức khỏe: https://vnexpress.net/suc-khoe-p4\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/suc-khoe-p4\n","Đang crawl trang 5 của danh mục Sức khỏe: https://vnexpress.net/suc-khoe-p5\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/suc-khoe-p5\n","Đang crawl trang 6 của danh mục Sức khỏe: https://vnexpress.net/suc-khoe-p6\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/suc-khoe-p6\n","Đang crawl trang 7 của danh mục Sức khỏe: https://vnexpress.net/suc-khoe-p7\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/suc-khoe-p7\n","Đang crawl trang 8 của danh mục Sức khỏe: https://vnexpress.net/suc-khoe-p8\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/suc-khoe-p8\n","Đang crawl trang 9 của danh mục Sức khỏe: https://vnexpress.net/suc-khoe-p9\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/suc-khoe-p9\n","Đang crawl trang 10 của danh mục Sức khỏe: https://vnexpress.net/suc-khoe-p10\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/suc-khoe-p10\n","Đang crawl trang 11 của danh mục Sức khỏe: https://vnexpress.net/suc-khoe-p11\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/suc-khoe-p11\n","Đang crawl trang 12 của danh mục Sức khỏe: https://vnexpress.net/suc-khoe-p12\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/suc-khoe-p12\n","Dữ liệu đã được lưu vào vnexpress_suc-khoe.csv\n","\n","Bắt đầu crawl danh mục: Pháp luật\n","Đang crawl trang 1 của danh mục Pháp luật: https://vnexpress.net/phap-luat\n","Đang crawl trang 2 của danh mục Pháp luật: https://vnexpress.net/phap-luat-p2\n","Đang crawl trang 3 của danh mục Pháp luật: https://vnexpress.net/phap-luat-p3\n","Đang crawl trang 4 của danh mục Pháp luật: https://vnexpress.net/phap-luat-p4\n","Đang crawl trang 5 của danh mục Pháp luật: https://vnexpress.net/phap-luat-p5\n","Đang crawl trang 6 của danh mục Pháp luật: https://vnexpress.net/phap-luat-p6\n","Đang crawl trang 7 của danh mục Pháp luật: https://vnexpress.net/phap-luat-p7\n","Đang crawl trang 8 của danh mục Pháp luật: https://vnexpress.net/phap-luat-p8\n","Đang crawl trang 9 của danh mục Pháp luật: https://vnexpress.net/phap-luat-p9\n","Đang crawl trang 10 của danh mục Pháp luật: https://vnexpress.net/phap-luat-p10\n","Đang crawl trang 11 của danh mục Pháp luật: https://vnexpress.net/phap-luat-p11\n","Đang crawl trang 12 của danh mục Pháp luật: https://vnexpress.net/phap-luat-p12\n","Dữ liệu đã được lưu vào vnexpress_phap-luat.csv\n","\n","Bắt đầu crawl danh mục: Kinh doanh\n","Đang crawl trang 1 của danh mục Kinh doanh: https://vnexpress.net/kinh-doanh\n","Đang crawl trang 2 của danh mục Kinh doanh: https://vnexpress.net/kinh-doanh-p2\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/kinh-doanh-p2\n","Đang crawl trang 3 của danh mục Kinh doanh: https://vnexpress.net/kinh-doanh-p3\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/kinh-doanh-p3\n","Đang crawl trang 4 của danh mục Kinh doanh: https://vnexpress.net/kinh-doanh-p4\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/kinh-doanh-p4\n","Đang crawl trang 5 của danh mục Kinh doanh: https://vnexpress.net/kinh-doanh-p5\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/kinh-doanh-p5\n","Đang crawl trang 6 của danh mục Kinh doanh: https://vnexpress.net/kinh-doanh-p6\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/kinh-doanh-p6\n","Đang crawl trang 7 của danh mục Kinh doanh: https://vnexpress.net/kinh-doanh-p7\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/kinh-doanh-p7\n","Đang crawl trang 8 của danh mục Kinh doanh: https://vnexpress.net/kinh-doanh-p8\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/kinh-doanh-p8\n","Đang crawl trang 9 của danh mục Kinh doanh: https://vnexpress.net/kinh-doanh-p9\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/kinh-doanh-p9\n","Đang crawl trang 10 của danh mục Kinh doanh: https://vnexpress.net/kinh-doanh-p10\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/kinh-doanh-p10\n","Đang crawl trang 11 của danh mục Kinh doanh: https://vnexpress.net/kinh-doanh-p11\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/kinh-doanh-p11\n","Đang crawl trang 12 của danh mục Kinh doanh: https://vnexpress.net/kinh-doanh-p12\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/kinh-doanh-p12\n","Dữ liệu đã được lưu vào vnexpress_kinh-doanh.csv\n","\n","Bắt đầu crawl danh mục: Khoa học\n","Đang crawl trang 1 của danh mục Khoa học: https://vnexpress.net/khoa-hoc\n","Đang crawl trang 2 của danh mục Khoa học: https://vnexpress.net/khoa-hoc-p2\n","Đang crawl trang 3 của danh mục Khoa học: https://vnexpress.net/khoa-hoc-p3\n","Đang crawl trang 4 của danh mục Khoa học: https://vnexpress.net/khoa-hoc-p4\n","Đang crawl trang 5 của danh mục Khoa học: https://vnexpress.net/khoa-hoc-p5\n","Đang crawl trang 6 của danh mục Khoa học: https://vnexpress.net/khoa-hoc-p6\n","Đang crawl trang 7 của danh mục Khoa học: https://vnexpress.net/khoa-hoc-p7\n","Đang crawl trang 8 của danh mục Khoa học: https://vnexpress.net/khoa-hoc-p8\n","Đang crawl trang 9 của danh mục Khoa học: https://vnexpress.net/khoa-hoc-p9\n","Đang crawl trang 10 của danh mục Khoa học: https://vnexpress.net/khoa-hoc-p10\n","Đang crawl trang 11 của danh mục Khoa học: https://vnexpress.net/khoa-hoc-p11\n","Đang crawl trang 12 của danh mục Khoa học: https://vnexpress.net/khoa-hoc-p12\n","Dữ liệu đã được lưu vào vnexpress_khoa-hoc.csv\n","\n","Bắt đầu crawl danh mục: Thể thao\n","Đang crawl trang 1 của danh mục Thể thao: https://vnexpress.net/the-thao\n","Đang crawl trang 2 của danh mục Thể thao: https://vnexpress.net/the-thao-p2\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/the-thao-p2\n","Đang crawl trang 3 của danh mục Thể thao: https://vnexpress.net/the-thao-p3\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/the-thao-p3\n","Đang crawl trang 4 của danh mục Thể thao: https://vnexpress.net/the-thao-p4\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/the-thao-p4\n","Đang crawl trang 5 của danh mục Thể thao: https://vnexpress.net/the-thao-p5\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/the-thao-p5\n","Đang crawl trang 6 của danh mục Thể thao: https://vnexpress.net/the-thao-p6\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/the-thao-p6\n","Đang crawl trang 7 của danh mục Thể thao: https://vnexpress.net/the-thao-p7\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/the-thao-p7\n","Đang crawl trang 8 của danh mục Thể thao: https://vnexpress.net/the-thao-p8\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/the-thao-p8\n","Đang crawl trang 9 của danh mục Thể thao: https://vnexpress.net/the-thao-p9\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/the-thao-p9\n","Đang crawl trang 10 của danh mục Thể thao: https://vnexpress.net/the-thao-p10\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/the-thao-p10\n","Đang crawl trang 11 của danh mục Thể thao: https://vnexpress.net/the-thao-p11\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/the-thao-p11\n","Đang crawl trang 12 của danh mục Thể thao: https://vnexpress.net/the-thao-p12\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/the-thao-p12\n","Dữ liệu đã được lưu vào vnexpress_the-thao.csv\n","\n","Bắt đầu crawl danh mục: Giải trí\n","Đang crawl trang 1 của danh mục Giải trí: https://vnexpress.net/giai-tri\n","Đang crawl trang 2 của danh mục Giải trí: https://vnexpress.net/giai-tri-p2\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/giai-tri-p2\n","Đang crawl trang 3 của danh mục Giải trí: https://vnexpress.net/giai-tri-p3\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/giai-tri-p3\n","Đang crawl trang 4 của danh mục Giải trí: https://vnexpress.net/giai-tri-p4\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/giai-tri-p4\n","Đang crawl trang 5 của danh mục Giải trí: https://vnexpress.net/giai-tri-p5\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/giai-tri-p5\n","Đang crawl trang 6 của danh mục Giải trí: https://vnexpress.net/giai-tri-p6\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/giai-tri-p6\n","Đang crawl trang 7 của danh mục Giải trí: https://vnexpress.net/giai-tri-p7\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/giai-tri-p7\n","Đang crawl trang 8 của danh mục Giải trí: https://vnexpress.net/giai-tri-p8\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/giai-tri-p8\n","Đang crawl trang 9 của danh mục Giải trí: https://vnexpress.net/giai-tri-p9\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/giai-tri-p9\n","Đang crawl trang 10 của danh mục Giải trí: https://vnexpress.net/giai-tri-p10\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/giai-tri-p10\n","Đang crawl trang 11 của danh mục Giải trí: https://vnexpress.net/giai-tri-p11\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/giai-tri-p11\n","Đang crawl trang 12 của danh mục Giải trí: https://vnexpress.net/giai-tri-p12\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/giai-tri-p12\n","Dữ liệu đã được lưu vào vnexpress_giai-tri.csv\n","\n","Bắt đầu crawl danh mục: Giáo dục\n","Đang crawl trang 1 của danh mục Giáo dục: https://vnexpress.net/giao-duc\n","Đang crawl trang 2 của danh mục Giáo dục: https://vnexpress.net/giao-duc-p2\n","Đang crawl trang 3 của danh mục Giáo dục: https://vnexpress.net/giao-duc-p3\n","Đang crawl trang 4 của danh mục Giáo dục: https://vnexpress.net/giao-duc-p4\n","Đang crawl trang 5 của danh mục Giáo dục: https://vnexpress.net/giao-duc-p5\n","Đang crawl trang 6 của danh mục Giáo dục: https://vnexpress.net/giao-duc-p6\n","Đang crawl trang 7 của danh mục Giáo dục: https://vnexpress.net/giao-duc-p7\n","Đang crawl trang 8 của danh mục Giáo dục: https://vnexpress.net/giao-duc-p8\n","Đang crawl trang 9 của danh mục Giáo dục: https://vnexpress.net/giao-duc-p9\n","Đang crawl trang 10 của danh mục Giáo dục: https://vnexpress.net/giao-duc-p10\n","Đang crawl trang 11 của danh mục Giáo dục: https://vnexpress.net/giao-duc-p11\n","Đang crawl trang 12 của danh mục Giáo dục: https://vnexpress.net/giao-duc-p12\n","Dữ liệu đã được lưu vào vnexpress_giao-duc.csv\n","\n","Bắt đầu crawl danh mục: Du lịch\n","Đang crawl trang 1 của danh mục Du lịch: https://vnexpress.net/du-lich\n","Đang crawl trang 2 của danh mục Du lịch: https://vnexpress.net/du-lich-p2\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/du-lich-p2\n","Đang crawl trang 3 của danh mục Du lịch: https://vnexpress.net/du-lich-p3\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/du-lich-p3\n","Đang crawl trang 4 của danh mục Du lịch: https://vnexpress.net/du-lich-p4\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/du-lich-p4\n","Đang crawl trang 5 của danh mục Du lịch: https://vnexpress.net/du-lich-p5\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/du-lich-p5\n","Đang crawl trang 6 của danh mục Du lịch: https://vnexpress.net/du-lich-p6\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/du-lich-p6\n","Đang crawl trang 7 của danh mục Du lịch: https://vnexpress.net/du-lich-p7\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/du-lich-p7\n","Đang crawl trang 8 của danh mục Du lịch: https://vnexpress.net/du-lich-p8\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/du-lich-p8\n","Đang crawl trang 9 của danh mục Du lịch: https://vnexpress.net/du-lich-p9\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/du-lich-p9\n","Đang crawl trang 10 của danh mục Du lịch: https://vnexpress.net/du-lich-p10\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/du-lich-p10\n","Đang crawl trang 11 của danh mục Du lịch: https://vnexpress.net/du-lich-p11\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/du-lich-p11\n","Đang crawl trang 12 của danh mục Du lịch: https://vnexpress.net/du-lich-p12\n","Không tìm thấy bài báo nào trên trang https://vnexpress.net/du-lich-p12\n","Dữ liệu đã được lưu vào vnexpress_du-lich.csv\n","Dữ liệu đã được lưu vào /content/drive/MyDrive/FILE/Năm 3/Khoa học dữ liệu/Nhóm 09 - PTDL Báo điện tử/vnexpress_all_articles.csv\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","import re\n","\n","# Danh mục cần crawl\n","categories = {\n","    'suc-khoe': 'Sức khỏe',\n","    'phap-luat': 'Pháp luật',\n","    'kinh-doanh': 'Kinh doanh',\n","    'khoa-hoc': 'Khoa học',\n","    'the-thao': 'Thể thao',\n","    'giai-tri': 'Giải trí',\n","    'giao-duc': 'Giáo dục',\n","    'du-lich': 'Du lịch'\n","}\n","\n","# Hàm crawl nội dung chi tiết của một bài báo\n","def crawl_article_content(url):\n","    try:\n","        headers = {\n","            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n","        }\n","        response = requests.get(url, headers=headers)\n","        response.raise_for_status()\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","\n","        # Lấy nội dung bài báo\n","        content_tag = soup.find('article', class_='fck_detail')\n","        content = content_tag.get_text(strip=True) if content_tag else \"Không tìm thấy nội dung\"\n","\n","        # Lấy tác giả\n","        author = \"Không rõ tác giả\"\n","\n","        # Tìm trong phần nội dung bài báo\n","        if content_tag:\n","            strong_tags = content_tag.find_all('strong')\n","            if strong_tags:\n","                last_strong = strong_tags[-1]\n","                text = last_strong.get_text(strip=True)\n","                if text:\n","                    author_match = re.match(r'^(.*?)(?:\\s*\\(Theo.*\\))?$', text)\n","                    if author_match:\n","                        author = author_match.group(1).strip()\n","                        if not author:\n","                            author = \"Không rõ tác giả\"\n","\n","        # Nếu không tìm thấy trong \u003carticle\u003e, thử tìm trong \u003cp class=\"author_mail\"\u003e\n","        if author == \"Không rõ tác giả\":\n","            author_mail_tag = soup.find('p', class_='author_mail')\n","            if author_mail_tag:\n","                strong_tag = author_mail_tag.find('strong')\n","                if strong_tag:\n","                    text = strong_tag.get_text(strip=True)\n","                    author_match = re.match(r'^(.*?)(?:\\s*\\(Theo.*\\))?$', text)\n","                    author = author_match.group(1).strip() if author_match else text\n","\n","        return content, author\n","\n","    except Exception as e:\n","        print(f\"Lỗi khi crawl nội dung bài báo {url}: {e}\")\n","        return \"Lỗi khi crawl nội dung\", \"Không rõ tác giả\"\n","\n","# Hàm crawl một trang trong danh mục\n","def crawl_page(url, category_name):\n","    try:\n","        headers = {\n","            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n","        }\n","        response = requests.get(url, headers=headers)\n","        response.raise_for_status()\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","\n","        # Tìm các bài báo\n","        articles = soup.find_all('h3', class_='title-news')\n","        if not articles:\n","            print(f\"Không tìm thấy bài báo nào trên trang {url}\")\n","            return []\n","\n","        data = []\n","        for article in articles:\n","            title_tag = article.find('a')\n","            if not title_tag:\n","                continue\n","            title = title_tag.text.strip()\n","            link = title_tag['href']\n","            if not link.startswith('https'):\n","                link = 'https://vnexpress.net' + link\n","\n","            description_tag = article.find_next('p', class_='description')\n","            description = description_tag.text.strip() if description_tag else \"Không có mô tả\"\n","\n","            content, author = crawl_article_content(link)\n","\n","            data.append({\n","                'title': title,\n","                'description': description,\n","                'content': content,\n","                'author': author,\n","                'link': link,\n","                'category': category_name\n","            })\n","\n","            time.sleep(1)\n","\n","        return data\n","    except Exception as e:\n","        print(f\"Lỗi khi crawl trang {url}: {e}\")\n","        return []\n","\n","# Hàm crawl toàn bộ danh mục\n","def crawl_category(category_key, category_name, max_articles=500):\n","    base_url = f\"https://vnexpress.net/{category_key}\"\n","    articles_per_page = 25\n","    pages_to_crawl = (max_articles // articles_per_page) + 1\n","    if pages_to_crawl \u003e 12:\n","        pages_to_crawl = 12\n","\n","    all_data = []\n","    for page in range(1, pages_to_crawl + 1):\n","        if page == 1:\n","            url = base_url\n","        else:\n","            url = f\"{base_url}-p{page}\"\n","\n","        print(f\"Đang crawl trang {page} của danh mục {category_name}: {url}\")\n","        page_data = crawl_page(url, category_name)\n","        all_data.extend(page_data)\n","\n","        if len(all_data) \u003e= max_articles:\n","            all_data = all_data[:max_articles]\n","            break\n","\n","        time.sleep(2)\n","\n","    return all_data\n","\n","# Hàm lưu dữ liệu vào file CSV\n","def save_to_csv(data, filename=\"vnexpress_articles.csv\"):\n","    if not data:\n","        print(\"Không có dữ liệu để lưu.\")\n","        return\n","\n","    df = pd.DataFrame(data)\n","    df.to_csv(filename, index=False, encoding='utf-8-sig')\n","    print(f\"Dữ liệu đã được lưu vào {filename}\")\n","\n","# Hàm chính\n","def main():\n","    all_articles = []\n","    for category_key, category_name in categories.items():\n","        print(f\"\\nBắt đầu crawl danh mục: {category_name}\")\n","        category_data = crawl_category(category_key, category_name, max_articles=600)\n","        all_articles.extend(category_data)\n","\n","        save_to_csv(category_data, f\"vnexpress_{category_key}.csv\")\n","\n","    save_to_csv(all_articles, \"/content/drive/MyDrive/FILE/Năm 3/Khoa học dữ liệu/Nhóm 09 - PTDL Báo điện tử/vnexpress_all_articles.csv\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","metadata":{"id":"PYcXj5Rfurtv"},"source":["# Crawl Nguồn Dân trí"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1hxLEILt4KY"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import time\n","# Không cần import Selenium cho Dân Trí trong trường hợp này\n","# vì hàm tìm link dùng requests đã hoạt động tốt\n","import csv\n","import re\n","\n","# --- Hàm trợ giúp chung (Requests) ---\n","def fetch_page_details(url):\n","    \"\"\"Gửi yêu cầu HTTP GET và phân tích HTML để trích xuất chi tiết.\"\"\"\n","    headers = {\n","        # Sử dụng User-Agent gần đây hơn\n","        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36'\n","    }\n","    try:\n","        response = requests.get(url, headers=headers, timeout=25) # Timeout hợp lý\n","        response.raise_for_status()\n","        response.encoding = 'utf-8' # Đảm bảo encoding UTF-8\n","        return BeautifulSoup(response.text, 'html.parser')\n","    except requests.Timeout:\n","        print(f\"Timeout khi tải trang chi tiết {url}\")\n","        return None\n","    except requests.RequestException as e:\n","        print(f\"Lỗi requests khi tải trang chi tiết {url}: {e}\")\n","        return None\n","    except Exception as e:\n","        print(f\"Lỗi không xác định khi tải {url}: {e}\")\n","        return None\n","\n","# --- Hàm tìm link Dân Trí (Giữ nguyên từ code của bạn) ---\n","def crawl_dantri_links(category, number_target=1000):\n","    \"\"\"Thu thập link bài báo từ các trang danh mục Dân Trí bằng Requests.\"\"\"\n","    base_url = f\"https://dantri.com.vn/{category}.htm\"\n","    links = set()\n","    page = 1\n","    max_retries = 3\n","    retries = 0\n","    max_pages_to_check = 100 # Giới hạn số trang kiểm tra để tránh vòng lặp vô hạn\n","\n","    print(f\"Bắt đầu thu thập link Dân Trí: {base_url} (Mục tiêu: {number_target})\")\n","\n","    while len(links) \u003c number_target and page \u003c= max_pages_to_check:\n","        url = base_url if page == 1 else f\"https://dantri.com.vn/{category}/trang-{page}.htm\"\n","        print(f\"   Đang quét trang: {url} (Đã tìm thấy: {len(links)}/{number_target})\")\n","\n","        # Sử dụng hàm fetch_page_details để lấy soup\n","        soup = fetch_page_details(url)\n","\n","        if not soup:\n","            retries += 1\n","            print(f\"   Không thể tải trang {url}, thử lại {retries}/{max_retries}...\")\n","            if retries \u003e= max_retries:\n","                print(f\"   Bỏ qua trang {url} sau {max_retries} lần thử thất bại.\")\n","                page += 1 # Chuyển sang trang tiếp theo nếu lỗi\n","                retries = 0\n","                continue\n","            time.sleep(5) # Chờ lâu hơn trước khi thử lại\n","            continue\n","\n","        retries = 0 # Reset retries nếu thành công\n","\n","        # Tìm các thẻ chứa link bài báo (Cập nhật selector nếu cần)\n","        # Thử nhiều selector phổ biến trên Dân Trí\n","        article_containers = soup.select('article.article-item h3.article-title a, div.article-item h3.article-title a, h2.news-item__title a')\n","        found_new_on_page = False\n","\n","        if not article_containers:\n","             print(f\"   Không tìm thấy thẻ bài báo nào trên trang {page}. Có thể đã hết trang hoặc cấu trúc thay đổi.\")\n","             break # Dừng nếu không tìm thấy bài nào trên trang\n","\n","        for a_tag in article_containers:\n","            if a_tag and 'href' in a_tag.attrs:\n","                link = a_tag['href']\n","                # Chuẩn hóa link (thêm domain nếu thiếu)\n","                if not link.startswith('http'):\n","                    link = f\"https://dantri.com.vn{link}\"\n","\n","                # Kiểm tra xem link có vẻ hợp lệ và thuộc danh mục không\n","                # Điều kiện f\"/{category}/\" trong link có thể quá chặt, xem xét lại nếu cần\n","                # Ví dụ: Chỉ cần link bắt đầu bằng domain và có định dạng .htm\n","                if link.startswith('https://dantri.com.vn/') and link.endswith('.htm') and link not in links:\n","                     # Thêm bộ lọc loại trừ video, chủ đề đặc biệt nếu cần\n","                     if \"/video-\" not in link and \"/topic/\" not in link:\n","                          links.add(link)\n","                          found_new_on_page = True\n","                          # print(f\"      + Link mới: {link}\") # Debug\n","                          if len(links) \u003e= number_target:\n","                              break # Đủ số lượng mục tiêu\n","\n","        if len(links) \u003e= number_target:\n","            print(f\"   Đã đạt mục tiêu {number_target} link.\")\n","            break # Thoát vòng lặp while\n","\n","        # Nếu trang có bài viết nhưng không tìm thấy link *mới* nào, có thể đã hết bài mới\n","        if not found_new_on_page and article_containers:\n","             print(f\"   Không tìm thấy link mới nào trên trang {page}. Dừng tìm kiếm cho danh mục này.\")\n","             break\n","\n","        page += 1\n","        time.sleep(1.5) # Nghỉ giữa các trang\n","\n","    print(f\"--- Hoàn tất tìm kiếm link cho [{category}]. Tìm thấy tổng cộng {len(links)} link duy nhất. ---\")\n","    return links\n","\n","# --- Hàm trích xuất chi tiết bài báo Dân Trí (Đã bỏ print xử lý link) ---\n","def extract_dantri_article_details(url, category):\n","    \"\"\"Trích xuất chi tiết bài báo Dân Trí.\"\"\"\n","    # print(f\"   Đang trích xuất chi tiết từ: {url}\") # \u003c--- ĐÃ XÓA\n","    soup = fetch_page_details(url)\n","    if not soup:\n","        return None\n","\n","    data = {\n","        \"title\": \"Không tìm thấy tiêu đề\",\n","        \"description\": \"Không tìm thấy mô tả\",\n","        \"content\": \"Không tìm thấy nội dung\",\n","        \"author\": \"Không tìm thấy tác giả\",\n","        \"link\": url,\n","        \"category\": category\n","    }\n","\n","    try:\n","        title_element = soup.find(\"h1\", class_=re.compile(r'\\b(dt-news__title|article-title|title-page|detail)\\b')) # Thêm title-page, detail\n","        if title_element: data[\"title\"] = title_element.get_text(strip=True)\n","\n","        desc_element = soup.find(['h2', 'p'], class_=re.compile(r'\\b(dt-news__sapo|singular-sapo|sapo)\\b'))\n","        if desc_element: data[\"description\"] = desc_element.get_text(strip=True)\n","\n","        author_tag_b = soup.select_one('div.author-wrap div.author-name a b')\n","        if author_tag_b:\n","            data[\"author\"] = author_tag_b.get_text(strip=True)\n","        else:\n","             author_element = soup.select_one('div.author-name p strong, p.author strong, div.author-name, p.author, .author') # Thêm .author\n","             if author_element:\n","                author_text = author_element.get_text(strip=True)\n","                author_text = re.sub(r'\\s*\\(.*?\\)|\\s*\\[.*?\\]|\\s*Theo\\s*|PV\\s*-\\s*|PV$', '', author_text, flags=re.IGNORECASE).strip()\n","                if author_text and len(author_text) \u003c 100:\n","                    data[\"author\"] = author_text\n","                elif soup.find(string=re.compile(r'Theo\\s+')):\n","                    author_match = soup.find(string=re.compile(r'Theo\\s+'))\n","                    if author_match and len(author_match.strip()) \u003c 100:\n","                         data[\"author\"] = author_match.strip()\n","\n","        content_div = soup.find(\"div\", class_=re.compile(r'\\b(singular-content|dt-news__content)\\b'))\n","        if content_div:\n","            elements_to_remove_selectors = [\n","                'figure', 'table', 'div.video', 'div.audio', '.article-related', '.article-event',\n","                'ul.related-topic', 'aside.article-topic', 'div.adv', 'div[id^=\"ads\"]',\n","                'div[class*=\"ads\"]', 'div.ecom-box', 'div.author-wrap', 'div.author-name',\n","                'p.author', '.singular-source', 'div.article-tags', 'div.tags-container',\n","                'div.bottom-article-action', 'div.social-share', '.like-share-bottom', '.social-pin',\n","                'blockquote', 'iframe', 'script', 'style', '#reference-articles',\n","                '.dantri-widget', 'p \u003e strong:contains(\"\u003e\u003e\u003e\")', '.content-box', '.singular-intro',\n","                'div.toolbar-content', '.controlbar'\n","            ]\n","            for selector in elements_to_remove_selectors:\n","                for unwanted in content_div.select(selector):\n","                     unwanted.decompose()\n","\n","            paragraphs = content_div.find_all('p', recursive=False)\n","            content_parts = []\n","            if not paragraphs:\n","                paragraphs = content_div.find_all('p')\n","\n","            for p in paragraphs:\n","                 if p.find_parent('figcaption'): continue\n","                 text = p.get_text(strip=True)\n","                 if text and len(text) \u003e 15 and not re.match(r'^(Ảnh|Nguồn|Đồ họa|Theo)\\s*:', text, re.IGNORECASE):\n","                     content_parts.append(text)\n","            clean_content = \"\\n\\n\".join(content_parts)\n","\n","            if not clean_content or len(clean_content) \u003c 100:\n","                 # print(\"   Nội dung từ \u003cp\u003e trống hoặc quá ngắn, thử fallback...\") # \u003c--- ĐÃ XÓA\n","                 clean_content_fallback = content_div.get_text(separator='\\n', strip=True)\n","                 lines = [line.strip() for line in clean_content_fallback.splitlines() if line.strip()]\n","                 filtered_lines = []\n","                 for line in lines:\n","                      if len(line) \u003e 15 and not re.match(r'^(Ảnh|Nguồn|Đồ họa|Theo)\\s*:|\\(Dân trí\\)|Thứ \\w+,|Bài viết cùng tác giả|Tin liên quan|Dòng sự kiện|Từ khoá:|Bình luận|Video:|Bạn nghĩ gì|Gửi bình luận|Quan tâm nhất|Mới nhất|Trả lời|Thích|Đọc thêm', line, re.IGNORECASE) and \"Ảnh:\" not in line and \"Clip:\" not in line:\n","                           filtered_lines.append(line)\n","                 clean_content = \"\\n\\n\".join(filtered_lines)\n","            data[\"content\"] = clean_content.strip()\n","        return data\n","    except Exception as e:\n","        print(f\"   Lỗi khi xử lý chi tiết bài báo Dân Trí {url}: {e}\") # Giữ lại báo lỗi\n","        return data\n","\n","# --- Thực thi chính ---\n","def main():\n","    # Cập nhật danh sách danh mục Dân Trí nếu cần\n","    dantri_categories = [\n","        \"kinh-doanh\", \"the-thao\", \"thoi-su\", \"suc-khoe\", \"giai-tri\",\n","        \"khoa-hoc\", \"the-gioi\", \"giao-duc\"\n","    ]\n","    number_target_per_category = 600 # Mục tiêu số bài viết mỗi danh mục\n","    all_articles_data = []\n","    collected_links = set() # Theo dõi link đã xử lý\n","\n","    print(\"\\n\" + \"=\"*10 + f\" BẮT ĐẦU THU THẬP DỮ LIỆU DÂN TRÍ (Mục tiêu: {number_target_per_category} bài/danh mục) \" + \"=\"*10)\n","    overall_start_time = time.time()\n","\n","    for category in dantri_categories:\n","        print(f\"\\n===\u003e\u003e\u003e Đang xử lý Danh mục: [{category}] \u003c\u003c\u003c===\")\n","        category_start_time = time.time()\n","        articles_added_in_category = 0\n","\n","        # --- Bước 1: Tìm kiếm Links bằng Requests (Hàm của bạn) ---\n","        article_links_found = crawl_dantri_links(category, number_target_per_category)\n","\n","        # --- Bước 2: Trích xuất chi tiết cho từng link ---\n","        if article_links_found:\n","            print(f\"\\n---\u003e Bắt đầu trích xuất chi tiết cho {len(article_links_found)} link tìm thấy trong [{category}]...\")\n","            links_to_process = list(article_links_found)\n","\n","            for i, link in enumerate(links_to_process):\n","                print(f\"   [{category} - {i+1}/{len(links_to_process)}] \", end=\"\")\n","\n","                if link in collected_links:\n","                    print(f\"Link đã xử lý: {link}. Bỏ qua.\")\n","                    continue\n","\n","                article_details = extract_dantri_article_details(link, category)\n","\n","                if article_details:\n","                    # Kiểm tra tính hợp lệ cơ bản\n","                    if article_details[\"title\"] != \"Không tìm thấy tiêu đề\" and \\\n","                       article_details[\"content\"] != \"Không tìm thấy nội dung\" and \\\n","                       len(article_details[\"content\"]) \u003e 50: # Yêu cầu độ dài nội dung tối thiểu (có thể điều chỉnh)\n","                        all_articles_data.append(article_details)\n","                        collected_links.add(link)\n","                        articles_added_in_category += 1\n","                        print(f\"   =\u003e OK. (Đã thêm {articles_added_in_category} bài mới cho danh mục)\")\n","                    else:\n","                        print(f\"   Bài báo không hợp lệ (thiếu TT/ND hoặc ND quá ngắn): {link}. Bỏ qua.\")\n","                else:\n","                    print(f\"   Trích xuất thất bại: {link}. Bỏ qua.\")\n","\n","                time.sleep(0.7) # Tăng delay một chút cho Dân Trí\n","            print(f\"---\u003e Hoàn tất trích xuất cho [{category}]. Đã thêm {articles_added_in_category} bài báo mới.\")\n","        else:\n","             print(f\"!!! Không tìm thấy link nào cho danh mục: [{category}] hoặc đã dừng tìm kiếm.\")\n","\n","\n","        category_end_time = time.time()\n","        print(f\"Thời gian xử lý danh mục [{category}]: {category_end_time - category_start_time:.2f} giây.\")\n","        print(\"-\" * 50)\n","        # time.sleep(5) # Delay giữa các danh mục nếu cần\n","\n","    overall_end_time = time.time()\n","    print(\"\\n\" + \"=\"*25)\n","    print(f\"*** HOÀN TẤT TOÀN BỘ QUÁ TRÌNH THU THẬP DỮ LIỆU DÂN TRÍ ***\")\n","    print(f\"*** Tổng số bài báo duy nhất đã trích xuất và hợp lệ: {len(all_articles_data)} ***\")\n","    total_minutes = (overall_end_time - overall_start_time) / 60\n","    print(f\"Tổng thời gian thực thi: {total_minutes:.2f} phút\")\n","    print(\"=\"*25)\n","\n","    # --- Bước 3: Lưu dữ liệu vào file CSV ---\n","    if all_articles_data:\n","        csv_filepath = '/content/drive/MyDrive/FILE/Năm 3/Khoa học dữ liệu/Nhóm 09 - PTDL Báo điện tử/dantri_articles_data.csv' # Tên file CSV\n","        fieldnames = ['category', 'link', 'title', 'author', 'description', 'content'] # Thứ tự cột\n","\n","        print(f\"\\nĐang lưu dữ liệu vào file CSV: {csv_filepath} ...\")\n","        try:\n","            with open(csv_filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:\n","                writer = csv.DictWriter(csvfile, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n","                writer.writeheader()\n","                writer.writerows(all_articles_data)\n","            print(f\"===\u003e Đã lưu dữ liệu thành công vào {csv_filepath}\")\n","        except IOError as e:\n","            print(f\"\\n!!! Lỗi IO khi lưu file CSV: {e}\")\n","        except Exception as e:\n","            print(f\"\\n!!! Lỗi không xác định khi lưu file CSV: {e}\")\n","    else:\n","        print(\"\\nKhông có dữ liệu bài báo nào hợp lệ để lưu vào file CSV.\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","metadata":{"id":"ddzkRVnduv7N"},"source":["# Crawl nguồn báo Tuổi trẻ"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"tjlJ-L-LOu20"},"outputs":[],"source":["pip install selenium"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AO6azxx-uCtb"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import time\n","from selenium import webdriver\n","from selenium.webdriver.chrome.options import Options\n","# from selenium.webdriver.chrome.service import Service # Không cần Service nữa\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException, WebDriverException # Thêm WebDriverException\n","import csv\n","import re\n","\n","# --- Hàm trợ giúp (Sử dụng Requests) ---\n","def fetch_page_details(url):\n","    \"\"\"Gửi yêu cầu HTTP GET và phân tích HTML để trích xuất chi tiết.\"\"\"\n","    headers = {\n","        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36'\n","    }\n","    try:\n","        response = requests.get(url, headers=headers, timeout=30)\n","        response.raise_for_status()\n","        response.encoding = 'utf-8'\n","        return BeautifulSoup(response.text, 'html.parser')\n","    except requests.Timeout:\n","        print(f\"Timeout khi tải trang chi tiết {url}\")\n","        return None\n","    except requests.RequestException as e:\n","        print(f\"Lỗi requests khi tải trang chi tiết {url}: {e}\")\n","        return None\n","    except Exception as e:\n","        print(f\"Lỗi không xác định khi tải {url}: {e}\")\n","        return None\n","\n","# --- Hàm trích xuất chi tiết bài báo Tuổi Trẻ ---\n","def extract_tuoitre_article_details(url, category):\n","    \"\"\"\n","    Trích xuất tiêu đề, mô tả, nội dung, tác giả, link và danh mục\n","    từ một URL bài báo Tuổi Trẻ.\n","    \"\"\"\n","    print(f\"   Đang trích xuất chi tiết từ: {url}\")\n","    soup = fetch_page_details(url)\n","    if not soup:\n","        return None\n","\n","    data = {\n","        \"title\": \"Không tìm thấy tiêu đề\",\n","        \"description\": \"Không tìm thấy mô tả\",\n","        \"content\": \"Không tìm thấy nội dung\",\n","        \"author\": \"Không tìm thấy tác giả\",\n","        \"link\": url,\n","        \"category\": category\n","    }\n","\n","    try:\n","        # Tiêu đề\n","        title_element = soup.find(\"h1\", class_=re.compile(r'\\b(detail-title|article-title)\\b'))\n","        if title_element:\n","             for span in title_element.find_all('span', class_='comment'):\n","                 span.decompose()\n","             data[\"title\"] = title_element.get_text(strip=True)\n","\n","        # Mô tả\n","        description_element = soup.find(\"h2\", class_=re.compile(r'\\b(detail-sapo|sapo)\\b'))\n","        if description_element: data[\"description\"] = description_element.get_text(strip=True)\n","\n","        # Tác giả\n","        author_div = soup.find(\"div\", class_=\"author-info\")\n","        if author_div:\n","            name_element = author_div.find(\"a\", class_=\"name\")\n","            if name_element:\n","                author_text = name_element.get_text(strip=True)\n","                more_authors_span = author_div.find(\"span\", class_=\"morenameauthor\")\n","                if more_authors_span:\n","                    author_text += \" \" + more_authors_span.get_text(strip=True)\n","                data[\"author\"] = author_text\n","            elif author_div.get_text(strip=True):\n","                 author_name = author_div.get_text(strip=True)\n","                 if \"ngày\" in author_name.lower():\n","                      author_name = author_name.split(\"ngày\")[0].strip()\n","                 data[\"author\"] = author_name\n","\n","        # Nội dung\n","        content_div = soup.find(\"div\", class_=re.compile(r'\\b(detail-content|content)\\b'))\n","        if content_div:\n","            elements_to_remove_selectors = [\n","                '.VCSortableInPreviewMode[type=\"RelatedNewsBox\"]', '.kbwscwl-relatedbox',\n","                '[type=\"RelatedOneNews\"]', 'div[id^=\"ObjectBoxContent_\"]',\n","                'figure.VCSortableInPreviewMode', 'figure', 'table', 'video',\n","                '.image-cms', '.pic', '.video-cms', '.VCSortableInPreviewMode[type=\"Photo\"]',\n","                '.quangcao', '.qcadt', 'div[id^=\"ads\"]', 'div[class^=\"ads\"]', '#InreadPc',\n","                '#sticky-player', '.wrapper-sticky-share', '.banner-contain', '.sticky-left',\n","                '.social-like-share','.share-tool-item', '.like-share-top', '.like-share-bottom',\n","                'script', 'style', 'noscript', 'iframe',\n","                'p \u003e strong:contains(\"TTO\")', 'p \u003e em:contains(\"TTO\")', '.author',\n","                'h4.related-news__title', '.readmore-body-box', '.source'\n","            ]\n","            for selector in elements_to_remove_selectors:\n","                for unwanted in content_div.select(selector):\n","                     unwanted.decompose()\n","\n","            main_text_elements = content_div.find_all(['p', 'h2', 'h3'], recursive=True)\n","            content_parts = []\n","            for element in main_text_elements:\n","                 if element.name == 'h2' and element.get('class') and ('detail-sapo' in element.get('class') or 'sapo' in element.get('class')):\n","                      continue\n","                 if element.find_parent('figcaption') or (element.get('class') and 'PhotoCMS_Caption' in element.get('class')):\n","                     continue\n","\n","                 text = element.get_text(separator='\\n', strip=True)\n","                 if text and len(text) \u003e 10 and not text.startswith((\"Ảnh:\", \"Đồ họa:\", \"Nguồn:\", \"*\", \"\u003e\u003e\", \"+\")):\n","                      text = re.sub(r'\\n\\s*\\n', '\\n\\n', text).strip()\n","                      content_parts.append(text)\n","\n","            clean_content = \"\\n\\n\".join(content_parts)\n","\n","            if not clean_content or len(clean_content) \u003c 50:\n","                 clean_content_fallback = content_div.get_text(separator='\\n', strip=True)\n","                 clean_content_fallback = re.sub(r'\\n\\s*\\n', '\\n\\n', clean_content_fallback).strip()\n","                 if len(clean_content_fallback) \u003e len(clean_content) + 100:\n","                     clean_content = clean_content_fallback\n","\n","            data[\"content\"] = clean_content.strip()\n","\n","        return data\n","\n","    except Exception as e:\n","        print(f\"   Lỗi khi xử lý chi tiết bài báo {url}: {e}\")\n","        return data\n","\n","# --- Hàm tìm link Tuổi Trẻ (Sử dụng cách khởi tạo Selenium cũ) ---\n","def crawl_tuoitre_links(category, number_target=600):\n","    \"\"\"Thu thập link bài báo từ các trang danh mục Tuổi Trẻ bằng Selenium (dựa vào PATH).\"\"\"\n","    base_url = f\"https://tuoitre.vn/{category}.htm\"\n","    links = set()\n","    max_clicks = 60\n","    clicks = 0\n","    max_retries = 3\n","    retries = 0\n","\n","    # Cấu hình Selenium Options\n","    chrome_options = Options()\n","    chrome_options.add_argument(\"--headless=new\")\n","    chrome_options.add_argument(\"--no-sandbox\")\n","    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n","    chrome_options.add_argument(\"--disable-gpu\")\n","    chrome_options.add_argument(\"--window-size=1920,1080\")\n","    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\")\n","    chrome_options.add_argument(\"--disable-notifications\")\n","    # chrome_options.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2}) # Tắt ảnh nếu muốn\n","\n","    driver = None\n","    try:\n","        # === SỬ DỤNG CÁCH KHỞI TẠO CŨ ===\n","        print(\"Đang thử khởi tạo WebDriver (dựa vào PATH)...\")\n","        # Selenium sẽ tự tìm chromedriver trong các thư mục thuộc PATH\n","        driver = webdriver.Chrome(options=chrome_options)\n","        print(\"Khởi tạo WebDriver thành công.\")\n","        # === KẾT THÚC KHỞI TẠO CŨ ===\n","\n","        print(f\"Bắt đầu thu thập link Tuổi Trẻ: {base_url} (Mục tiêu: {number_target})\")\n","        driver.get(base_url)\n","        WebDriverWait(driver, 20).until(\n","             EC.presence_of_element_located((By.CSS_SELECTOR, 'h3.box-title-text a, h3.title-news a'))\n","        )\n","        time.sleep(2)\n","\n","        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n","\n","        # --- Vòng lặp thu thập link ---\n","        while len(links) \u003c number_target and clicks \u003c max_clicks:\n","            initial_link_count = len(links)\n","\n","            driver.execute_script(\"window.scrollBy(0, 500);\")\n","            time.sleep(0.5)\n","\n","            article_elements = driver.find_elements(By.CSS_SELECTOR, 'h3.box-title-text a, h3.title-news a')\n","            print(f\"   Trang hiện tại có {len(article_elements)} phần tử link tiềm năng.\")\n","\n","            for element in article_elements:\n","                try:\n","                    link = element.get_attribute('href')\n","                    if link and isinstance(link, str) and \\\n","                       link.startswith('https://tuoitre.vn/') and \\\n","                       link.endswith(\".htm\") and \\\n","                       \"?page=\" not in link and \\\n","                       link not in links:\n","                        if not re.search(r'/(video|infographics|podcast|quiz|longform|e-magazine|livestream)/', link):\n","                            links.add(link)\n","                            if len(links) \u003e= number_target: break\n","                except Exception:\n","                    pass\n","\n","            print(f\"   =\u003e Đã thu thập: {len(links)} / {number_target} link duy nhất cho [{category}].\")\n","\n","            if len(links) \u003e= number_target:\n","                print(f\"   Đã đạt mục tiêu {number_target} link cho danh mục [{category}].\")\n","                break\n","\n","            # --- Xử lý nút \"Xem thêm\" hoặc cuộn trang ---\n","            try:\n","                load_more_button = WebDriverWait(driver, 8).until(\n","                    EC.element_to_be_clickable((By.CSS_SELECTOR, \"a.btn-readmore.view-more\"))\n","                )\n","                driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\", load_more_button)\n","                time.sleep(1)\n","                print(f\"   Đang thử nhấp 'Xem thêm' lần thứ {clicks + 1}/{max_clicks}...\")\n","                driver.execute_script(\"arguments[0].click();\", load_more_button)\n","                clicks += 1\n","                print(f\"   Đã nhấp 'Xem thêm'. Đang chờ nội dung mới tải...\")\n","                time.sleep(5)\n","                retries = 0\n","                last_height = driver.execute_script(\"return document.body.scrollHeight\")\n","\n","            except TimeoutException:\n","                print(\"   Không tìm thấy nút 'Xem thêm' hoặc nút không thể nhấp. Thử cuộn trang...\")\n","                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n","                time.sleep(3)\n","                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n","                if new_height == last_height:\n","                    print(\"   Đã cuộn đến cuối trang và không có nội dung mới. Dừng.\")\n","                    break\n","                last_height = new_height\n","\n","            except ElementClickInterceptedException:\n","                 print(\"   Nhấp 'Xem thêm' bị chặn. Thử cuộn và thử lại...\")\n","                 driver.execute_script(\"window.scrollBy(0, 400);\")\n","                 time.sleep(2)\n","                 retries += 1\n","                 if retries \u003e= max_retries:\n","                     print(f\"   Không thể nhấp 'Xem thêm' sau {max_retries} lần thử lại. Dừng danh mục này.\")\n","                     break\n","                 continue\n","\n","            except Exception as e_click:\n","                print(f\"   Lỗi không mong muốn khi click/cuộn: {e_click}. Dừng danh mục này.\")\n","                break\n","\n","            if len(links) == initial_link_count and clicks \u003e 0 and retries == 0:\n","                 if clicks \u003e 2:\n","                      print(\"   Không có link mới được thêm sau vài lần nhấp 'Xem thêm'. Có thể đã hết bài. Dừng.\")\n","                      break\n","\n","    # --- Xử lý lỗi chung của Selenium ---\n","    except WebDriverException as e_selenium: # Bắt lỗi cụ thể hơn của Selenium\n","        print(f\"!!! Lỗi WebDriver khi xử lý danh mục [{category}]: {e_selenium}\")\n","        if \"net::ERR_NAME_NOT_RESOLVED\" in str(e_selenium):\n","            print(\"   Lỗi mạng hoặc không thể phân giải tên miền. Kiểm tra kết nối internet.\")\n","        elif \"session deleted because of page crash\" in str(e_selenium) or \\\n","             \"target window already closed\" in str(e_selenium):\n","            print(\"   Trình duyệt bị crash hoặc đóng đột ngột.\")\n","        else:\n","            print(\"   Lỗi này có thể do chromedriver không tìm thấy trong PATH hoặc phiên bản không tương thích.\")\n","            print(\"   Vui lòng kiểm tra lại cài đặt chromedriver và biến môi trường PATH.\")\n","        # Không cần return ở đây vì finally sẽ chạy\n","    except Exception as e_main_selenium: # Bắt các lỗi khác\n","        print(f\"!!! Lỗi không mong muốn trong quá trình Selenium cho danh mục [{category}]: {e_main_selenium}\")\n","    finally:\n","        if driver:\n","            print(f\"Đang đóng trình duyệt Selenium cho danh mục [{category}]...\")\n","            try:\n","                driver.quit()\n","            except Exception as e_quit:\n","                print(f\"   Lỗi khi đóng trình duyệt: {e_quit}\")\n","\n","    print(f\"--- Hoàn tất tìm kiếm link cho [{category}]. Tìm thấy tổng cộng {len(links)} link duy nhất. ---\")\n","    return links\n","\n","\n","# --- Thực thi chính ---\n","def main():\n","    tuoitre_categories = [\n","        \"kinh-doanh\", \"phap-luat\", \"the-thao\", \"suc-khoe\",\n","        \"giai-tri\", \"khoa-hoc\", \"the-gioi\", \"giao-duc\", \"du-lich\"\n","    ]\n","    number_target_per_category = 600\n","    all_articles_data = []\n","    collected_links = set()\n","\n","    print(\"\\n\" + \"=\"*10 + f\" BẮT ĐẦU THU THẬP DỮ LIỆU TUỔI TRẺ (Mục tiêu: {number_target_per_category} bài/danh mục) \" + \"=\"*10)\n","    overall_start_time = time.time()\n","\n","    for category in tuoitre_categories:\n","        print(f\"\\n===\u003e\u003e\u003e Đang xử lý Danh mục: [{category}] \u003c\u003c\u003c===\")\n","        category_start_time = time.time()\n","        articles_added_in_category = 0\n","\n","        # --- Bước 1: Tìm kiếm Links ---\n","        article_links_found = crawl_tuoitre_links(category, number_target_per_category)\n","\n","        # --- Bước 2: Trích xuất chi tiết ---\n","        if article_links_found:\n","            print(f\"\\n---\u003e Bắt đầu trích xuất chi tiết cho {len(article_links_found)} link tìm thấy trong [{category}]...\")\n","            links_to_process = list(article_links_found)\n","\n","            for i, link in enumerate(links_to_process):\n","                print(f\"   [{category} - {i+1}/{len(links_to_process)}] \", end=\"\")\n","\n","                if link in collected_links:\n","                    print(f\"Link đã xử lý: {link}. Bỏ qua.\")\n","                    continue\n","\n","                article_details = extract_tuoitre_article_details(link, category)\n","\n","                if article_details:\n","                    if article_details[\"title\"] != \"Không tìm thấy tiêu đề\" and \\\n","                       article_details[\"content\"] != \"Không tìm thấy nội dung\" and \\\n","                       len(article_details[\"content\"]) \u003e 100:\n","                        all_articles_data.append(article_details)\n","                        collected_links.add(link)\n","                        articles_added_in_category += 1\n","                        print(f\"   =\u003e OK. (Đã thêm {articles_added_in_category} bài mới cho danh mục)\")\n","                    else:\n","                        print(f\"   Bài báo không hợp lệ (thiếu TT/ND hoặc ND quá ngắn): {link}. Bỏ qua.\")\n","                else:\n","                    print(f\"   Trích xuất thất bại: {link}. Bỏ qua.\")\n","\n","                time.sleep(0.5)\n","            print(f\"---\u003e Hoàn tất trích xuất cho [{category}]. Đã thêm {articles_added_in_category} bài báo mới.\")\n","        else:\n","            # Kiểm tra xem hàm crawl_tuoitre_links có trả về set rỗng do lỗi WebDriver không\n","            # (Lỗi này đã được in ra trong hàm crawl_tuoitre_links)\n","            if not article_links_found: # Chỉ in thêm nếu thực sự không tìm thấy link (không phải do lỗi WebDriver)\n","                 print(f\"!!! Không tìm thấy link nào trên trang hoặc đã dừng sớm cho danh mục: [{category}]\")\n","\n","\n","        category_end_time = time.time()\n","        print(f\"Thời gian xử lý danh mục [{category}]: {category_end_time - category_start_time:.2f} giây.\")\n","        print(\"-\" * 50)\n","\n","    overall_end_time = time.time()\n","    print(\"\\n\" + \"=\"*25)\n","    print(f\"*** HOÀN TẤT TOÀN BỘ QUÁ TRÌNH THU THẬP DỮ LIỆU ***\")\n","    print(f\"*** Tổng số bài báo duy nhất đã trích xuất và hợp lệ: {len(all_articles_data)} ***\")\n","    total_minutes = (overall_end_time - overall_start_time) / 60\n","    print(f\"Tổng thời gian thực thi: {total_minutes:.2f} phút\")\n","    print(\"=\"*25)\n","\n","    # --- Bước 3: Lưu dữ liệu vào file CSV ---\n","    if all_articles_data:\n","        csv_filepath = '/content/drive/MyDrive/FILE/Năm 3/Khoa học dữ liệu/Nhóm 09 - PTDL Báo điện tử/tuoitre_articles_data.csv' # Đổi tên file\n","        fieldnames = ['category', 'link', 'title', 'author', 'description', 'content']\n","\n","        print(f\"\\nĐang lưu dữ liệu vào file CSV: {csv_filepath} ...\")\n","        try:\n","            with open(csv_filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:\n","                writer = csv.DictWriter(csvfile, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n","                writer.writeheader()\n","                writer.writerows(all_articles_data)\n","            print(f\"===\u003e Đã lưu dữ liệu thành công vào {csv_filepath}\")\n","        except IOError as e:\n","            print(f\"\\n!!! Lỗi IO khi lưu file CSV: {e}\")\n","        except Exception as e:\n","            print(f\"\\n!!! Lỗi không xác định khi lưu file CSV: {e}\")\n","    else:\n","        print(\"\\nKhông có dữ liệu bài báo nào hợp lệ để lưu vào file CSV.\")\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","metadata":{"id":"suO0me9KvnJc"},"source":["# Tổng hợp thành file crawl duy nhất"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"5_7FLURPuKSt"},"outputs":[],"source":["import pandas as pd\n","\n","# Đường dẫn đến 3 file CSV (thay đổi theo tên file thực tế của bạn)\n","file1 = '/content/drive/MyDrive/FILE/Năm 3/Khoa học dữ liệu/Nhóm 09 - PTDL Báo điện tử/vnexpress_all_articles.csv'\n","file2 = '/content/drive/MyDrive/FILE/Năm 3/Khoa học dữ liệu/Nhóm 09 - PTDL Báo điện tử/dantri_articles_data.csv'\n","file3 = '/content/drive/MyDrive/FILE/Năm 3/Khoa học dữ liệu/Nhóm 09 - PTDL Báo điện tử/tuoitre_articles_data.csv'\n","\n","# Đọc 3 file CSV\n","df1 = pd.read_csv(file1)\n","df2 = pd.read_csv(file2)\n","df3 = pd.read_csv(file3)\n","\n","# Gộp 3 DataFrame thành 1 bằng cách nối theo chiều dọc\n","df_combined = pd.concat([df1, df2, df3], ignore_index=True)\n","\n","# Kiểm tra dữ liệu sau khi gộp\n","print(\"Số dòng của file gộp:\", len(df_combined))\n","print(\"Thông tin cơ bản của file gộp:\")\n","print(df_combined.info())\n","print(\"\\nDữ liệu mẫu (5 dòng đầu):\")\n","print(df_combined.head())\n","\n","# Lưu file gộp thành CSV mới\n","output_file = '/content/drive/MyDrive/FILE/Năm 3/Khoa học dữ liệu/Nhóm 09 - PTDL Báo điện tử/crawl_data_articles.csv'\n","df_combined.to_csv(output_file, index=False, encoding='utf-8-sig')\n","print(f\"Đã gộp 3 file và lưu vào: {output_file}\")"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}